{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import SantaFeAgent, SantaFeFood, SantaFeWorld\n",
    "from src import terminals\n",
    "from grammaticalevolutiontools.evolution import cross_over, mutation\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines colors for the agents and objects in the WorldAnimation\n",
    "AGENT_CMAP = {SantaFeAgent: 'red'}\n",
    "OBJ_CMAP = {SantaFeFood: 'lime'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a simple implementation of a genetic algorithm, for \n",
    "# demonstration purposes\n",
    "\n",
    "world = SantaFeWorld()\n",
    "best_agent = None\n",
    "best_score = -1\n",
    "\n",
    "num_generations = 10\n",
    "num_agents = 100\n",
    "num_to_keep = 50\n",
    "num_rand = 10\n",
    "num_ticks = 100\n",
    "\n",
    "chance_to_keep_best_agent = 0.7\n",
    "chance_of_mutation = 0.7\n",
    "\n",
    "agents = [SantaFeAgent() for _ in range(num_agents)]\n",
    "top_agents_heap = []\n",
    "best_agent = None\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    print(f\"GENERATION {gen + 1}: \")\n",
    "    top_agents_heap.clear()\n",
    "\n",
    "    print('running and scoring agents...')\n",
    "    for agent in tqdm(agents):\n",
    "        # reset the world with the current agent and run the simulation\n",
    "        world.reset_with_agent(agent)\n",
    "        world.tick(num_ticks)\n",
    "\n",
    "        # keep track of n agents with highest scores from this generation\n",
    "        # using a heap (used for creating next generation).\n",
    "        if len(top_agents_heap) < num_to_keep:\n",
    "            heapq.heappush(top_agents_heap, (agent.score + 1, agent))\n",
    "            # (score + 1) ensures each of the top 10 agents has a non-zero\n",
    "            # chance of being chosen to reproduce.\n",
    "        elif (agent.score + 1) > top_agents_heap[0][0]:\n",
    "            heapq.heapreplace(top_agents_heap, (agent.score + 1, agent))\n",
    "\n",
    "        # track agent with overall best score across all generations\n",
    "        if agent.score > best_score:\n",
    "            best_agent = agent\n",
    "            best_score = best_agent.score\n",
    "\n",
    "    print('selecting agents...')\n",
    "    # weight each top agent by its score\n",
    "    weights, top_agents = zip(*top_agents_heap)\n",
    "\n",
    "    # add some random new agents to add variation (give weight of 1).\n",
    "    breeding_pool = list(top_agents) + [SantaFeAgent() for _ in range(num_rand)]\n",
    "    selection_weights = list(weights) + [1]*num_rand\n",
    "\n",
    "    # chance of putting the overall best agent back into the breeding pool\n",
    "    if random.random() < chance_to_keep_best_agent:\n",
    "        breeding_pool += [best_agent]\n",
    "        selection_weights += [best_score]\n",
    "\n",
    "    print('creating new generation...')\n",
    "    new_agents = []\n",
    "    while len(new_agents) < num_agents:\n",
    "        # randomly select two agents, \n",
    "        agent1, agent2 = random.choices(\n",
    "            breeding_pool, \n",
    "            weights=selection_weights, \n",
    "            k=2\n",
    "            )\n",
    "        \n",
    "        # cross over their programs\n",
    "        prog1, prog2 = cross_over.cross_over_programs(\n",
    "            agent1.program, \n",
    "            agent2.program\n",
    "            )\n",
    "        \n",
    "        # mutation\n",
    "        if random.random() < chance_of_mutation:\n",
    "            mutation.mutate_terminals(\n",
    "                prog1, \n",
    "                num_mutations=2, \n",
    "                terminal_types=terminals\n",
    "                )\n",
    "\n",
    "        new_agents.append(SantaFeAgent(prog1))\n",
    "        new_agents.append(SantaFeAgent(prog2))\n",
    "\n",
    "    agents = new_agents\n",
    "\n",
    "\n",
    "print(best_score)\n",
    "print(best_agent.program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the best agent in the world, this time recording each frame, and\n",
    "# create an animation\n",
    "world.reset_with_agent(best_agent, recording_on=True)\n",
    "world.tick(num_ticks)\n",
    "anim = world.generate_animation(\n",
    "    bg_color='black', \n",
    "    agent_colors=AGENT_CMAP, \n",
    "    obj_colors=OBJ_CMAP,\n",
    "    arrow_color='blue'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This animation can be replayed again and again\n",
    "anim.play(pause=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
